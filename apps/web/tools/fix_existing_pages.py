#!/usr/bin/env python3
"""
ê¸°ì¡´ í˜ì´ì§€ë“¤ì˜ SEO ë¬¸ì œ ì¼ê´„ ìˆ˜ì •
- ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ ìˆ˜ì •
- ì¢…ë£Œëœ ì´ë²¤íŠ¸ì— noindex ì¶”ê°€
- Event ìŠ¤í‚¤ë§ˆ â†’ Article ìŠ¤í‚¤ë§ˆ ì „í™˜ (ì¢…ë£Œ/ë‚ ì§œì—†ìŒ)
"""

import os
import re
import json
from datetime import datetime
from bs4 import BeautifulSoup

PAGES_DIR = os.path.join(os.path.dirname(__file__), "../public/pages")

def get_event_status(start_date_iso, end_date_iso):
    """ì´ë²¤íŠ¸ ìƒíƒœ ë°˜í™˜: 'active', 'upcoming', 'expired'"""
    today = datetime.today().date()
    try:
        if end_date_iso:
            end_date = datetime.strptime(end_date_iso, "%Y-%m-%d").date()
            if end_date < today:
                return "expired"
        if start_date_iso:
            start_date = datetime.strptime(start_date_iso, "%Y-%m-%d").date()
            if start_date > today:
                return "upcoming"
        return "active"
    except ValueError:
        return "active"

def extract_dates_from_jsonld(content):
    """JSON-LDì—ì„œ ë‚ ì§œ ì¶”ì¶œ"""
    start_match = re.search(r'"startDate"\s*:\s*"([^"]*)"', content)
    end_match = re.search(r'"endDate"\s*:\s*"([^"]*)"', content)

    start = start_match.group(1) if start_match else ""
    end = end_match.group(1) if end_match else ""

    # ì˜ëª»ëœ í˜•ì‹ ì •ë¦¬ (ì˜ˆ: "2025-09-7ê¹Œì§€" â†’ "")
    if start and not re.match(r'^\d{4}-\d{2}-\d{2}$', start):
        start = ""
    if end and not re.match(r'^\d{4}-\d{2}-\d{2}$', end):
        end = ""

    return start, end

def extract_info_from_page(content):
    """í˜ì´ì§€ì—ì„œ ì •ë³´ ì¶”ì¶œ"""
    soup = BeautifulSoup(content, 'html.parser')

    # ì œëª©
    h1 = soup.find('h1')
    title = h1.get_text(strip=True) if h1 else ""

    # ì¸ë„¤ì¼
    img = soup.find('img', class_='thumbnail')
    thumbnail = img.get('src', '') if img else ""

    # ì§€ì 
    branch = ""
    if 'songdo' in content.lower():
        branch = "ì†¡ë„"
    elif 'gimpo' in content.lower():
        branch = "ê¹€í¬"
    elif 'spaceone' in content.lower():
        branch = "ìŠ¤í˜ì´ìŠ¤ì›"

    # description
    meta_desc = soup.find('meta', attrs={'name': 'description'})
    description = meta_desc.get('content', '') if meta_desc else title

    return title, description, thumbnail, branch

def generate_article_schema(title, description, thumbnail, update_date):
    """Article ìŠ¤í‚¤ë§ˆ ìƒì„±"""
    schema = {
        "@context": "https://schema.org",
        "@type": "Article",
        "headline": title,
        "description": description,
        "image": thumbnail if thumbnail else "",
        "datePublished": update_date,
        "dateModified": update_date,
        "author": {
            "@type": "Organization",
            "name": "í˜„ëŒ€ë°±í™”ì "
        },
        "publisher": {
            "@type": "Organization",
            "name": "í˜„ëŒ€ í”„ë¦¬ë¯¸ì—„ ì•„ìš¸ë ›",
            "url": "https://www.ehyundai.com"
        }
    }
    return f'<script type="application/ld+json">\n  {json.dumps(schema, ensure_ascii=False, indent=2)}\n  </script>'

def fix_page(filepath):
    """ë‹¨ì¼ í˜ì´ì§€ ìˆ˜ì •"""
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()

    original_content = content
    changes = []

    # 1. ë‚ ì§œ ì¶”ì¶œ
    start_date, end_date = extract_dates_from_jsonld(content)
    status = get_event_status(start_date, end_date)

    # 2. noindex ì²˜ë¦¬ (ì¢…ë£Œëœ ì´ë²¤íŠ¸)
    has_noindex = 'name="robots" content="noindex' in content
    if status == "expired" and not has_noindex:
        # viewport ë©”íƒ€ íƒœê·¸ ë‹¤ìŒì— noindex ì¶”ê°€
        noindex_tag = '<meta name="robots" content="noindex, follow">'
        content = content.replace(
            '<meta name="viewport"',
            f'{noindex_tag}\n  <meta name="viewport"'
        )
        changes.append("noindex ì¶”ê°€")

    # 3. ì˜ëª»ëœ JSON-LD ìˆ˜ì • (ë¹ˆ ë‚ ì§œ, ë¹„í‘œì¤€ í˜•ì‹)
    # Event ìŠ¤í‚¤ë§ˆê°€ ìˆê³  (ì¢…ë£Œëê±°ë‚˜ ë‚ ì§œê°€ ì—†ìœ¼ë©´) Articleë¡œ êµì²´
    if '"@type": "Event"' in content or '"@type":"Event"' in content:
        has_valid_dates = bool(start_date and end_date)

        if not has_valid_dates or status == "expired":
            title, description, thumbnail, branch = extract_info_from_page(content)
            update_date = datetime.today().strftime('%Y-%m-%d')

            # ê¸°ì¡´ Event ìŠ¤í‚¤ë§ˆ ì œê±° í›„ Article ìŠ¤í‚¤ë§ˆë¡œ êµì²´
            # JSON-LD ë¸”ë¡ ì°¾ê¸°
            pattern = r'<script type="application/ld\+json">\s*\{[^}]*"@type"\s*:\s*"Event"[^<]*</script>'
            new_schema = generate_article_schema(title, description, thumbnail, update_date)

            if re.search(pattern, content, re.DOTALL):
                content = re.sub(pattern, new_schema, content, flags=re.DOTALL)
                changes.append("Eventâ†’Article ìŠ¤í‚¤ë§ˆ ì „í™˜")

    # 4. ì˜ëª»ëœ endDate í˜•ì‹ ìˆ˜ì • (ì˜ˆ: "2025-09-7ê¹Œì§€")
    bad_date_pattern = r'"endDate"\s*:\s*"[^"]*ê¹Œì§€"'
    if re.search(bad_date_pattern, content):
        content = re.sub(bad_date_pattern, '"endDate": ""', content)
        changes.append("ì˜ëª»ëœ endDate í˜•ì‹ ìˆ˜ì •")

    # ë³€ê²½ì‚¬í•­ ìˆìœ¼ë©´ ì €ì¥
    if content != original_content:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        return changes
    return []

def main():
    print("ğŸ”§ ê¸°ì¡´ í˜ì´ì§€ SEO ë¬¸ì œ ì¼ê´„ ìˆ˜ì • ì‹œì‘...")

    fixed_count = 0
    noindex_count = 0
    schema_count = 0

    pages = [f for f in os.listdir(PAGES_DIR) if f.endswith('.html')]
    total = len(pages)

    for i, filename in enumerate(pages, 1):
        filepath = os.path.join(PAGES_DIR, filename)
        changes = fix_page(filepath)

        if changes:
            fixed_count += 1
            if "noindex ì¶”ê°€" in changes:
                noindex_count += 1
            if "Eventâ†’Article ìŠ¤í‚¤ë§ˆ ì „í™˜" in changes:
                schema_count += 1
            print(f"  [{i}/{total}] {filename}: {', '.join(changes)}")

    print(f"\nâœ… ì™„ë£Œ!")
    print(f"   - ìˆ˜ì •ëœ íŒŒì¼: {fixed_count}ê°œ")
    print(f"   - noindex ì¶”ê°€: {noindex_count}ê°œ")
    print(f"   - ìŠ¤í‚¤ë§ˆ ì „í™˜: {schema_count}ê°œ")

if __name__ == "__main__":
    main()
